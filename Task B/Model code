import os
import json
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard
from sklearn.metrics import classification_report
import numpy as np

# GPU setup: allow growth so TF doesn't allocate all the RAM
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    for gpu in gpus:
        tf.config.experimental.set_memory_growth(gpu, True)

def build_generators(base_dir, img_size=224, batch_size=32, val_split=0.15):
    train_dir = os.path.join(base_dir, 'train')
    # single datagen with split
    datagen = ImageDataGenerator(
        rescale=1./255,
        horizontal_flip=True,
        zoom_range=0.2,
        rotation_range=15,
        validation_split=val_split
    )
    train_gen = datagen.flow_from_directory(
        train_dir,
        target_size=(img_size, img_size),
        batch_size=batch_size,
        class_mode='categorical',
        subset='training'      # <â€” training
    )
    val_gen = datagen.flow_from_directory(
        train_dir,
        target_size=(img_size, img_size),
        batch_size=batch_size,
        class_mode='categorical',
        subset='validation',   # <â€” validation
        shuffle=False
    )
    return train_gen, val_gen


def build_model(num_classes, img_size=224):
    base = MobileNetV2(
        weights='imagenet',
        include_top=False,
        input_shape=(img_size, img_size, 3)
)
    x = GlobalAveragePooling2D()(base.output)
    out = Dense(num_classes, activation='softmax')(x)
    model = Model(base.input, out)
    model.compile(
        optimizer=Adam(1e-4),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

def main():
    BASE_DIR   = 'Task_B'       # adjust if needed
    IMG_SIZE   = 224
    BATCH_SIZE = 32
    EPOCHS     = 100

    # Generators
    train_gen, val_gen = build_generators('Task_B', IMG_SIZE, BATCH_SIZE)

    # Save classâ†”index map for inference
    with open('class_indices.json', 'w') as f:
        json.dump(train_gen.class_indices, f, indent=4)
    idx2label = {v:k for k,v in train_gen.class_indices.items()}

    # Build & compile
    model = build_model(len(train_gen.class_indices), IMG_SIZE)

    # Callbacks
    ckpt = ModelCheckpoint(
        'face_id_best.h5', monitor='val_accuracy',
        save_best_only=True, verbose=1
    )
    early = EarlyStopping(
        monitor='val_loss', patience=5,
        restore_best_weights=True, verbose=1
    )
    tb = TensorBoard(log_dir='logs', histogram_freq=1)

    # Train
    history = model.fit(
        train_gen,
        validation_data=val_gen,
        epochs=EPOCHS,
        callbacks=[ckpt, early, tb]
    )

    # Save final model
    model.save('face_id_final.h5')

    # Evaluate on val set
    val_preds = model.predict(val_gen)
    y_true = val_gen.classes
    y_pred = np.argmax(val_preds, axis=1)
    print(classification_report(
        y_true, y_pred,
        target_names=[idx2label[i] for i in sorted(idx2label)]
    ))

    print("ðŸ‘‰ To visualize with TensorBoard:\n"
          "   tensorboard --logdir logs\n")

if __name__ == '__main__':
    main()
