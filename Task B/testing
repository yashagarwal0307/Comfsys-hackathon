import os
import shutil
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import accuracy_score
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image

def flatten_dataset(read_only_dir, output_dir): # use this code  if using kaggle/ collab or if you are saving the file after flattening in some other file otherwise use the code in preprocessing
    os.makedirs(output_dir, exist_ok=True)

    for identity_folder in os.listdir(read_only_dir):
        identity_path = os.path.join(read_only_dir, identity_folder)
        if not os.path.isdir(identity_path):
            continue

        for subdir, _, files in os.walk(identity_path):
            for file in files:
                if file.lower().endswith(('.jpg', '.png')):
                    src = os.path.join(subdir, file)
                    # Flatten: put all images in one output folder per identity
                    dst_identity_dir = os.path.join(output_dir, identity_folder)
                    os.makedirs(dst_identity_dir, exist_ok=True)
                    dst = os.path.join(dst_identity_dir, file)
                    
                    if not os.path.exists(dst):
                        shutil.copy2(src, dst)

    print("Dataset flattening complete.")


flatten_dataset(
    "/kaggle/input/comfsys-challenge/Comys_Hackathon5/Task_B/train",
    "/kaggle/working/flat_train"
)

IMG_SIZE = (160, 160)
VAL_PATH = "Task_B/val" # do use the flattened dataset here

# === Load embedding model ===
model = load_model("face_embedding_model.h5", compile=False)

# === Extract embeddings ===
def extract_embeddings(folder_path):
    embeddings = []
    labels = []
    for person in os.listdir(folder_path):
        person_folder = os.path.join(folder_path, person)
        for fname in os.listdir(person_folder):
            img_path = os.path.join(person_folder, fname)
            img = image.load_img(img_path, target_size=IMG_SIZE)
            img = image.img_to_array(img) / 255.0
            emb = model.predict(np.expand_dims(img, axis=0), verbose=0)[0]
            embeddings.append(emb)
            labels.append(person)
    return np.array(embeddings), np.array(labels)

# === Verification by Nearest Neighbor ===
def compute_verification_accuracy(embeddings, labels):
    predictions = []
    for i, emb in enumerate(embeddings):
        others = np.delete(embeddings, i, axis=0)
        other_labels = np.delete(labels, i, axis=0)
        sims = cosine_similarity([emb], others)[0]
        pred = other_labels[np.argmax(sims)]
        predictions.append(pred)
    acc = accuracy_score(labels, predictions)
    return acc,labels,predictions

# === Run Evaluation ===
embeddings, labels = extract_embeddings(VAL_PATH)
acc, y_true, y_pred = compute_verification_accuracy(embeddings, labels)
print(f"Top1 Accuracy: {acc * 100:.2f}%")
print("F1 Score:", f1_score(y_true, y_pred, average='macro'))
